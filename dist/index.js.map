{"version":3,"sources":["../src/index.ts"],"sourcesContent":["import * as csv from 'csv-stream';\r\nimport { open } from 'node:fs/promises';\r\nimport * as pe from 'post-entity';\r\nimport { removeStopwords } from 'stopword';\r\n\r\nconst file = process.argv[2] || '';\r\nconst filter = parseInt(process.argv[3] || '5');\r\n\r\nif (file === '') {\r\n  throw new RangeError();\r\n}\r\n\r\nconst tokens = {};\r\n// Initialize the parser\r\nconst options = {\r\n  delimiter: '\\t',\r\n  endLine: '\\n',\r\n  columnOffset: 0,\r\n  escapeChar: '\"',\r\n  enclosedChar: '\"',\r\n};\r\n\r\nconst csvStream = csv.createStream(options);\r\n\r\nlet prompt = `Using a list of words where the number after the comma is how frequently the word is used, give a detailed and critical summary (without using any positive terminology) about the personality, interests, fears, and hopes of the person using these words from the list (and account for frequency): \r\n\r\n`;\r\n\r\nconst alphanumOnly = /[^a-z\\-]/g;\r\n\r\n/**\r\n *\r\n */\r\nasync function main() {\r\n  const fd = await open(file, 'r');\r\n  const stream = fd.createReadStream();\r\n  stream\r\n    .pipe(csvStream)\r\n\r\n    .on('data', function (data) {\r\n      // outputs an object containing a set of key/value pair representing a line found in the csv file.\r\n      if (data.retweet !== 'False') {\r\n        return;\r\n      }\r\n\r\n      if (data.language !== 'en') {\r\n        return;\r\n      }\r\n      const tweet = data.tweet.toLowerCase();\r\n\r\n      const text = pe\r\n        .process(tweet)\r\n        .filter((tweet) => tweet.type === 'text')\r\n        .map((tweet) => tweet.raw.trim());\r\n\r\n      for (const words of text) {\r\n        const split = removeStopwords(words.split(' '));\r\n        for (const element of split) {\r\n          const token = element.trim().replace(alphanumOnly, '');\r\n\r\n          if (token !== '') {\r\n            if (tokens[token] === undefined) {\r\n              tokens[token] = 0;\r\n            }\r\n            tokens[token] += 1;\r\n          }\r\n        }\r\n      }\r\n    })\r\n\r\n    .on('close', function () {\r\n      const keys = Object.keys(tokens);\r\n\r\n      for (const key of keys) {\r\n        if (tokens[key] < filter) {\r\n          continue;\r\n        }\r\n        prompt += `${key}:${tokens[key]} `;\r\n      }\r\n\r\n      console.log(prompt);\r\n    });\r\n}\r\n\r\nmain();\r\n"],"mappings":"2cAAA,IAAAA,EAAqB,yBACrBC,EAAqB,uBACrBC,EAAoB,0BACpBC,EAAgC,oBAE1BC,EAAO,QAAQ,KAAK,CAAC,GAAK,GAC1BC,EAAS,SAAS,QAAQ,KAAK,CAAC,GAAK,GAAG,EAE9C,GAAID,IAAS,GACX,MAAM,IAAI,WAGZ,IAAME,EAAS,CAAC,EAEVC,EAAU,CACd,UAAW,IACX,QAAS;AAAA,EACT,aAAc,EACd,WAAY,IACZ,aAAc,GAChB,EAEMC,EAAgB,eAAaD,CAAO,EAEtCE,EAAS;AAAA;AAAA,EAIPC,EAAe,YAKrB,eAAeC,GAAO,EACT,QAAM,QAAKP,EAAM,GAAG,GACb,iBAAiB,EAEhC,KAAKI,CAAS,EAEd,GAAG,OAAQ,SAAUI,EAAM,CAM1B,GAJIA,EAAK,UAAY,SAIjBA,EAAK,WAAa,KACpB,OAEF,IAAMC,EAAQD,EAAK,MAAM,YAAY,EAE/BE,EACH,UAAQD,CAAK,EACb,OAAQA,GAAUA,EAAM,OAAS,MAAM,EACvC,IAAKA,GAAUA,EAAM,IAAI,KAAK,CAAC,EAElC,QAAWE,KAASD,EAAM,CACxB,IAAME,KAAQ,mBAAgBD,EAAM,MAAM,GAAG,CAAC,EAC9C,QAAWE,KAAWD,EAAO,CAC3B,IAAME,EAAQD,EAAQ,KAAK,EAAE,QAAQP,EAAc,EAAE,EAEjDQ,IAAU,KACRZ,EAAOY,CAAK,IAAM,SACpBZ,EAAOY,CAAK,EAAI,GAElBZ,EAAOY,CAAK,GAAK,IAIzB,CAAC,EAEA,GAAG,QAAS,UAAY,CACvB,IAAMC,EAAO,OAAO,KAAKb,CAAM,EAE/B,QAAWc,KAAOD,EACZb,EAAOc,CAAG,EAAIf,IAGlBI,GAAU,GAAGW,KAAOd,EAAOc,CAAG,MAGhC,QAAQ,IAAIX,CAAM,CACpB,CAAC,CACL,CAEAE,EAAK","names":["csv","import_promises","pe","import_stopword","file","filter","tokens","options","csvStream","prompt","alphanumOnly","main","data","tweet","text","words","split","element","token","keys","key"]}